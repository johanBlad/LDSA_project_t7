{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hostname for this machine: host-192-168-2-247-ldsa\n"
     ]
    }
   ],
   "source": [
    "## Load context\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "\n",
    "hostname = os.uname()[1]\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# BEN'S MASTER: 192.168.2.87\n",
    "# OUR MASTER:   192.168.2.203\n",
    "\n",
    "# New API\n",
    "conf = (SparkConf()    \n",
    "   .setMaster(\"spark://192.168.2.203:7077\")  \n",
    "   .setAppName(f\"load_local_comments; hostname: {hostname}\")    \n",
    "   .set(\"spark.executor.cores\",2)  \n",
    "   .set(\"spark.dynamicAllocation.enabled\", False)  \n",
    "   .set(\"spark.shuffle.service.enabled\", False))\n",
    "\n",
    "#spark_context = SparkContext(conf = conf)  \n",
    "spark_session = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "spark_context.uiWebUrl\n",
    "print(f'hostname for this machine: {hostname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_fraction = 0.05\n",
    "\n",
    "df = spark_session.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .json('hdfs://192.168.2.203:9000/RC_2010-01')\\\n",
    "    .sample(False, load_fraction, 1234)\\\n",
    "    .cache()\n",
    "\n",
    "sampled_count = df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting timer. Fraction of dataset is 0.05 and sampled size is 144339\n"
     ]
    }
   ],
   "source": [
    "### START TIMER\n",
    "\n",
    "print(f'Starting timer. Fraction of dataset is {load_fraction} and sampled size is {sampled_count}')\n",
    "start_clock = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- archived: boolean (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created_utc: string (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- downs: long (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- removal_reason: string (nullable = true)\n",
      " |-- retrieved_on: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- score_hidden: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- ups: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fp = df.drop(*['permalink', 'gilded', 'author_flair_css_class', 'can_gild', 'author_flair_text', 'author_cakeday'])\n",
    "df_fp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter functions\n",
    "to_basket_unique = lambda comment: list(set((re.sub(r'\\W+', ' ', comment).lower().strip().split(' '))))\n",
    "udf_to_basket_unique = F.udf(to_basket_unique, ArrayType(StringType()))\n",
    "\n",
    "\n",
    "def filter_words(basket):\n",
    "    stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "    stopwords += ['https', 'www', 'one', 'would', 'come', 'really', 'also', 'com', 'gt', 'r', '737yli']\n",
    "    stopwords += ['get', 'even', 'make', 'go', 'still', 'could', 'got', 'goes', '2', 'first', 'going', 'right', 'sure', 'something', 'http', 'well', 'back', 'though']\n",
    "    return [word for word in basket if word not in stopwords]\n",
    "    \n",
    "udf_filter_words = F.udf(filter_words, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp1 = df_fp.withColumn('body', udf_filter_words(udf_to_basket_unique('body'))).select('body').filter(F.size(F.col('body')) > 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpGrowth = FPGrowth(itemsCol=\"body\", minSupport=0.01, minConfidence=0.05)\n",
    "model = fpGrowth.fit(df_fp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|     items| freq|\n",
      "+----------+-----+\n",
      "|    [like]|14524|\n",
      "|  [people]|10526|\n",
      "|   [think]| 9331|\n",
      "|    [time]| 7722|\n",
      "|    [know]| 7474|\n",
      "|    [good]| 6763|\n",
      "|    [much]| 6220|\n",
      "|     [way]| 5746|\n",
      "|     [see]| 5560|\n",
      "|    [want]| 5096|\n",
      "|     [say]| 4689|\n",
      "|   [never]| 4431|\n",
      "|   [thing]| 4336|\n",
      "|[actually]| 4185|\n",
      "|  [things]| 3975|\n",
      "|    [work]| 3949|\n",
      "|     [use]| 3933|\n",
      "|    [need]| 3838|\n",
      "|    [take]| 3743|\n",
      "|  [pretty]| 3740|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display frequent itemsets.\n",
    "model.freqItemsets.sort(\"freq\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-------------------+------------------+\n",
      "|     antecedent|consequent|         confidence|              lift|\n",
      "+---------------+----------+-------------------+------------------+\n",
      "|[think, people]|    [like]| 0.3877214668314792|2.2877008085277657|\n",
      "|  [think, like]|  [people]|0.37370929308975376| 3.042538978711061|\n",
      "|        [think]|    [like]| 0.2698531775801093|1.5922340787030174|\n",
      "|        [think]|  [people]|0.26010073947058193| 2.117599569676084|\n",
      "|        [think]|    [know]|0.15614617940199335|1.7903745164854996|\n",
      "|        [think]|    [time]|0.15346693816311222|1.7031411810106483|\n",
      "|        [think]|    [good]| 0.1401779016182617|1.7762569325713697|\n",
      "|        [think]|    [much]|0.13728432108027006| 1.891455701545965|\n",
      "|        [think]|     [way]| 0.1336405529953917|1.9931420936383717|\n",
      "|        [think]|     [see]|0.11960132890365449|1.8434307703338992|\n",
      "|        [think]|     [say]|0.11081341764012431| 2.025245777672368|\n",
      "|        [think]|    [want]|0.10899153359768514|1.8328586057144471|\n",
      "|        [think]|  [things]|0.10459757796592005| 2.255018525520868|\n",
      "|        [think]|   [thing]|0.09891758653949202|1.9550139330430922|\n",
      "+---------------+----------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display generated association rules.\n",
    "antecedent = 'think'\n",
    "\n",
    "model.associationRules.filter(F.array_contains('antecedent', antecedent)).sort('confidence', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                body|          prediction|\n",
      "+--------------------+--------------------+\n",
      "|[cat, dog, consid...|                  []|\n",
      "|[center, question...|      [people, like]|\n",
      "|[someone, continu...|      [people, like]|\n",
      "|[czechs, system, ...|                  []|\n",
      "|[someone, handout...|[think, know, peo...|\n",
      "|[level, developme...|[think, know, peo...|\n",
      "|[person, least, t...|[think, point, ac...|\n",
      "|[specific, trying...|      [like, people]|\n",
      "|[assume, thing, w...|[know, people, ti...|\n",
      "|[plate, comments,...|                  []|\n",
      "|[god, new, gibbon...|              [like]|\n",
      "|[interesting, cre...|                  []|\n",
      "|[fine, protecting...|[people, like, th...|\n",
      "|[beach, place, fo...|      [like, people]|\n",
      "|[house, visit, bo...|                  []|\n",
      "|[gold, fuckload, ...|                  []|\n",
      "|[promote, kills, ...|[point, actually,...|\n",
      "|[komedi, dizi, da...|                  []|\n",
      "|[30, median, quit...|              [like]|\n",
      "|[anything, joke, ...|              [like]|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform examines the input items against all the association rules and summarize the\n",
    "# consequents as prediction\n",
    "model.transform(df_fp1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished. Experiment run on 144339 comments. Runtime resulted in 136.61919116973877 seconds.\n"
     ]
    }
   ],
   "source": [
    "### END TIMER\n",
    "\n",
    "end_clock = time()\n",
    "\n",
    "runtime = end_clock - start_clock\n",
    "\n",
    "print(f'Run finished. Experiment run on {sampled_count} comments. Runtime resulted in {runtime} seconds.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
