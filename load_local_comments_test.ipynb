{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-47a672d8b394>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-47a672d8b394>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    spark_context = spark_session.sparkContext\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Load context\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "hostname = os.uname()[1]\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# BEN'S MASTER: 192.168.2.87\n",
    "# OUR MASTER:   192.168.2.203\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.203:7077\") \\\n",
    "        .appName(f\"load_local_comments; hostname: {hostname}\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.blockManager.port\", \"10025\")\\\n",
    "        .config(\"spark.driver.blockManager.port\", \"10026\")\\\n",
    "        .config(\"spark.driver.port\", \"10027\")\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.executor.cores\",6)\\\n",
    "        .getOrCreate()\n",
    "        \n",
    "#spark_session = SparkSession\\\n",
    "#        .builder\\\n",
    "#        .master(\"spark://192.168.2.203:7077\") \\\n",
    "#        .appName(f\"load_local_comments; hostname: {hostname}\")\\\n",
    "#        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "#        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "#        .config(\"spark.executor.cores\",6)\\\n",
    "#        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "spark_context.uiWebUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext  \n",
    "## Load context\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "hostname = os.uname()[1]\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "conf = (SparkConf()    \n",
    "   .setMaster(\"spark://192.168.2.203:7077\")  \n",
    "   .setAppName(\"mytest\")    \n",
    "   .set(\"spark.executor.cores\",1)  \n",
    "   .set(\"spark.dynamicAllocation.enabled\", False)  \n",
    "   .set(\"spark.shuffle.service.enabled\", False))  \n",
    "#spark_context = SparkContext(conf = conf)  \n",
    "spark_session = SparkSession.builder.config(conf=conf).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "\n",
    "df_pd = pd.read_json(\"sample_reddit_comments.json\", lines=True)\n",
    "df = spark_session.createDataFrame(df_pd).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "udf_strip_lower = F.udf(lambda comment: (re.sub(r'\\W+', ' ', comment).lower().strip()), 'string')\n",
    "df_1 = df.select('body').withColumn('body', udf_strip_lower('body'))\n",
    "\n",
    "#df.select('body').withColumn('body', f.lower(f.col('body'))).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1.withColumn('word', f.explode(f.split(f.col('body'), ' ')))\\\n",
    "    .groupBy('word')\\\n",
    "    .count()\\\n",
    "    .sort('count', ascending=False)\n",
    "\n",
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
