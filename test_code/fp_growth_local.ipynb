{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hostname for this machine: host-192-168-2-247-ldsa\n"
     ]
    }
   ],
   "source": [
    "## Load context\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "\n",
    "hostname = os.uname()[1]\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# BEN'S MASTER: 192.168.2.87\n",
    "# OUR MASTER:   192.168.2.203\n",
    "\n",
    "# New API\n",
    "conf = (SparkConf()    \n",
    "   .setMaster(\"spark://192.168.2.203:7077\")  \n",
    "   .setAppName(f\"load_local_comments; hostname: {hostname}\")    \n",
    "   .set(\"spark.executor.cores\",2)  \n",
    "   .set(\"spark.dynamicAllocation.enabled\", False)  \n",
    "   .set(\"spark.shuffle.service.enabled\", False))\n",
    "\n",
    "#spark_context = SparkContext(conf = conf)  \n",
    "spark_session = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "spark_context.uiWebUrl\n",
    "print(f'hostname for this machine: {hostname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = spark_context.textFile(\"hdfs://192.168.2.203:9000/RC_2005-12\")\n",
    "load_fraction = 0.01\n",
    "\n",
    "df = spark_session.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .json('hdfs://192.168.2.203:9000/RC_2010-01')\\\n",
    "    .sample(False, load_fraction, 1234)\\\n",
    "    .cache()\n",
    "\n",
    "\n",
    "sampled_count = df.count()\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only local file\n",
    "\n",
    "#df_pd = pd.read_json(\"sample_reddit_comments.json\", lines=True)\n",
    "#df = spark_session.createDataFrame(df_pd).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting timer. Fraction of dataset is 0.01 and sampled size is 28813\n"
     ]
    }
   ],
   "source": [
    "### START TIMER\n",
    "\n",
    "print(f'Starting timer. Fraction of dataset is {load_fraction} and sampled size is {sampled_count}')\n",
    "start_clock = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- archived: boolean (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created_utc: string (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- downs: long (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- removal_reason: string (nullable = true)\n",
      " |-- retrieved_on: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- score_hidden: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- ups: long (nullable = true)\n",
      "\n",
      "+--------+-------------------+--------------------+----------------+-----------+-------------+-----+------+-------+--------+----------+----------+--------------+------------+-----+------------+-------------+------------+---+\n",
      "|archived|             author|                body|controversiality|created_utc|distinguished|downs|edited|     id| link_id|      name| parent_id|removal_reason|retrieved_on|score|score_hidden|    subreddit|subreddit_id|ups|\n",
      "+--------+-------------------+--------------------+----------------+-----------+-------------+-----+------+-------+--------+----------+----------+--------------+------------+-----+------------+-------------+------------+---+\n",
      "|    true|             rchase|That cat does not...|               0| 1262304013|         null|    0| false|c0i12vi|t3_akdsr|t1_c0i12vi|  t3_akdsr|          null|  1426171564|    1|       false|   reddit.com|        t5_6|  1|\n",
      "|    true|          adamdecaf|So, it's not even...|               0| 1262304078|         null|    0| false|c0i12ws|t3_ak954|t1_c0i12ws|t1_c0i0rs4|          null|  1426171564|    2|       false|   technology|    t5_2qh16|  2|\n",
      "|    true|             _oogle| Way to be creepers.|               0| 1262304117|         null|    0| false|c0i12xq|t3_akdvm|t1_c0i12xq|  t3_akdvm|          null|  1426171564|    4|       false|    AskReddit|    t5_2qh1i|  4|\n",
      "|    true|          [deleted]|       Take a dump.\n",
      "|               0| 1262304171|         null|    0| false|c0i12z2|t3_akdvk|t1_c0i12z2|  t3_akdvk|          null|  1426171565|    2|       false|    AskReddit|    t5_2qh1i|  2|\n",
      "|    true| therealjerrystaute|Man, you need to ...|               0| 1262304276|         null|    0| false|c0i131u|t3_akdqq|t1_c0i131u|  t3_akdqq|          null|  1426171567|    0|       false|    AskReddit|    t5_2qh1i|  0|\n",
      "|    true|      BudMasterSess|The only thing I ...|               0| 1262304297|         null|    0| false|c0i132d|t3_akc2y|t1_c0i132d|t1_c0i0una|          null|  1426171567|    1|       false|          WTF|    t5_2qh61|  1|\n",
      "|    true|             Dafuzz|   so 3 or 4 months?|               0| 1262304319|         null|    0| false|c0i132w|t3_akd86|t1_c0i132w|t1_c0i0wpy|          null|  1426171567|    5|       false|    AskReddit|    t5_2qh1i|  5|\n",
      "|    true|             fizz23|interesting solut...|               0| 1262304336|         null|    0| false|c0i133g|t3_akdze|t1_c0i133g|t1_c0i12t1|          null|  1426171567|    2|       false|    AskReddit|    t5_2qh1i|  2|\n",
      "|    true|          [deleted]|In about a months...|               0| 1262304339|         null|    0| false|c0i133l|t3_ak8uh|t1_c0i133l|t1_c0i0so8|          null|  1426171567|    2|       false|       videos|    t5_2qh1e|  2|\n",
      "|    true|          adamdecaf|If you're never g...|               0| 1262304345|         null|    0| false|c0i133n|t3_aka0f|t1_c0i133n|  t3_aka0f|          null|  1426171567|    1|       false|   philosophy|    t5_2qh5b|  1|\n",
      "|    true|      joshbydefault|                14th|               0| 1262304411|         null|    0| false|c0i1359|t3_ake21|t1_c0i1359|t1_c0i12mr|          null|  1426171567|    3|       false|    AskReddit|    t5_2qh1i|  3|\n",
      "|    true|          [deleted]|           [deleted]|               0| 1262304502|         null|    0| false|c0i137m|t3_akcm3|t1_c0i137m|t1_c0i0rfw|          null|  1426171569|    1|       false|     politics|    t5_2cneq|  1|\n",
      "|    true|     FurryHolocaust|When internet mod...|               0| 1262304678|         null|    0| false|c0i13cl|t3_ak8iy|t1_c0i13cl|t1_c0i0vz1|          null|  1426171570|   -1|       false|   reddit.com|        t5_6| -1|\n",
      "|    true|brainwashedsociety5|your 4 im 5 you h...|               0| 1262304689|         null|    0| false|c0i13cw|t3_akcbt|t1_c0i13cw|t1_c0i1201|          null|  1426171570|    2|       false|     politics|    t5_2cneq|  2|\n",
      "|    true|           tidderor|I think the origi...|               0| 1262304742|         null|    0| false|c0i13ej|t3_akcvn|t1_c0i13ej|t1_c0i1322|          null|  1426171570|    5|       false|    AskReddit|    t5_2qh1i|  5|\n",
      "|    true|               jrrl|The land where we...|               0| 1262304754|         null|    0| false|c0i13eu|t3_aka5e|t1_c0i13eu|t1_c0i0wit|          null|  1426171571|    3|       false|entertainment|    t5_2qh0f|  3|\n",
      "|    true|         sohanlon07|Apple Juice becau...|               0| 1262304830|         null|    0| false|c0i13h9|t3_ake61|t1_c0i13h9|  t3_ake61|          null|  1426171571|    2|       false|   reddit.com|        t5_6|  2|\n",
      "|    true|         merlin2232|So did we come to...|               0| 1262304831|         null|    0| false|c0i13ha|t3_ak483|t1_c0i13ha|  t3_ak483|          null|  1426171571|    1|       false|   reddit.com|        t5_6|  1|\n",
      "|    true|          [deleted]|           [deleted]|               0| 1262304838|         null|    0| false|c0i13hk|t3_akbsd|t1_c0i13hk|  t3_akbsd|          null|  1426171572|    0|       false|         pics|    t5_2qh0u|  0|\n",
      "|    true|          [deleted]|Yes. I do.\n",
      "\n",
      "White...|               0| 1262304903|         null|    0| false|c0i13jm|t3_akc2y|t1_c0i13jm|t1_c0i0vah|          null|  1426171572|    0|       false|          WTF|    t5_2qh61|  0|\n",
      "+--------+-------------------+--------------------+----------------+-----------+-------------+-----+------+-------+--------+----------+----------+--------------+------------+-----+------------+-------------+------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fp = df.drop(*['permalink', 'gilded', 'author_flair_css_class', 'can_gild', 'author_flair_text', 'author_cakeday'])\n",
    "df_fp.printSchema()\n",
    "df_fp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter functions\n",
    "to_basket_unique = lambda comment: list(set((re.sub(r'\\W+', ' ', comment).lower().strip().split(' '))))\n",
    "udf_to_basket_unique = F.udf(to_basket_unique, ArrayType(StringType()))\n",
    "\n",
    "\n",
    "def filter_words(basket):\n",
    "    stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "    stopwords += ['https', 'www', 'one', 'would', 'come', 'really', 'also', 'com', 'gt', 'r', '737yli']\n",
    "    stopwords += ['get', 'even', 'make', 'go', 'still', 'could', 'got', 'goes', '2', 'first', 'going', 'right', 'sure', 'something', 'http', 'well', 'back', 'though']\n",
    "    return [word for word in basket if word not in stopwords]\n",
    "    \n",
    "udf_filter_words = F.udf(filter_words, ArrayType(StringType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(body=['cat', 'dog', 'consider', 'instead', 'realizes', 'truth']),\n",
       " Row(body=['person', 'least', 'things', 'involving', 'particular', 'cliche', 'dozens', 'specific', 'picking', 'genres', 'event', 'forced', 'oranges', 'sex', 'like', 'man', 'love', 'happen', 'comparing', 'interesting', 'much', 'surely', 'apples', 'need', 'pick', 'different', 'people', 'select', 'absolute']),\n",
       " Row(body=['assume', 'thing', 'want', 'plane', 'however', 'contact', 'al', 'captured', 'qaeda', 'terrorists', 'think', 'lost']),\n",
       " Row(body=['interesting', 'create', 'grep', 'folder', 'searching', 'index', 'solution']),\n",
       " Row(body=['fine', 'protecting', 'seem', 'based', 'given', 'protect', 'matter', 'morals', 'create', 'expect', 'wrong', 'ground', 'sort', 'awareness', 'know', 'murder', 'never', 'self', 'learn', 'long']),\n",
       " Row(body=['someone', 'downvotes', 'act', 'clueless', 'start', 'banning', 'write', 'fight', 'previous', 'distribute', 'script', 'greasemonkey', 'mass', 'like', 'fascists', 'op', 'soze', 'mods', 'posts', 'sperger', 'automatically', 'internet', 'people']),\n",
       " Row(body=['youtube', 'im', 'watch', '5', 'fuckec', 'mifs41pwl6g', '4', 'v', 'say']),\n",
       " Row(body=['advocating', 'things', 'false', 'probably', 'thinks', 'wailing', 'either', 'point', 'report', 'settled', 'kids', 'dad', 'op', 'call', 'think', 'original', '911', 'away', 'incident', 'late', 'file']),\n",
       " Row(body=['cunts', 'anyway', 'new', 'pointless', 'juice', 'celebration', 'another', 'excuse', 'fuck', 'years', 'man', 'flu', 'people', 'apple']),\n",
       " Row(body=['happy', 'year', 'conclusion', 'ten', 'two', 'new', 'thousand', 'twenty'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fp1 = df_fp.withColumn('body', udf_filter_words(udf_to_basket_unique('body'))).select('body').filter(F.size(F.col('body')) > 5)\n",
    "df_fp1.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpGrowth = FPGrowth(itemsCol=\"body\", minSupport=0.01, minConfidence=0.01)\n",
    "model = fpGrowth.fit(df_fp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like', 'people', 'think', 'time', 'know', 'good', 'much', 'see', 'way', 'want', 'say', 'thing', 'never', 'actually', 'use', 'work', 'things', 'pretty', 'need', 'take', 'years', 'us', 'lot', 'someone', 'better', 'said', 'many', 'point', 'look', 'around']\n"
     ]
    }
   ],
   "source": [
    "#from functools import reduce\n",
    "extract_top = [el for lis in map(lambda x: x.items, model.freqItemsets.sort(\"freq\", ascending = False).select('items').take(30)) for el in lis]\n",
    "#extract_top = reduce(list.__add__, map(lambda x: x.items, model.freqItemsets.sort(\"freq\", ascending = False).select('items').take(30)))\n",
    "print(extract_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of dataset: 28813 comments\n",
      "+----------+----+\n",
      "|     items|freq|\n",
      "+----------+----+\n",
      "|    [like]|2885|\n",
      "|  [people]|2123|\n",
      "|   [think]|1894|\n",
      "|    [time]|1539|\n",
      "|    [know]|1461|\n",
      "|    [good]|1331|\n",
      "|    [much]|1243|\n",
      "|     [see]|1128|\n",
      "|     [way]|1116|\n",
      "|    [want]|1005|\n",
      "|     [say]| 941|\n",
      "|   [thing]| 871|\n",
      "|   [never]| 867|\n",
      "|[actually]| 850|\n",
      "|     [use]| 813|\n",
      "|    [work]| 803|\n",
      "|  [things]| 763|\n",
      "|  [pretty]| 739|\n",
      "|    [need]| 726|\n",
      "|    [take]| 722|\n",
      "+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count\n",
    "c = df.count()\n",
    "print(f'Total size of dataset: {c} comments')\n",
    "\n",
    "# Display frequent itemsets.\n",
    "model.freqItemsets.sort(\"freq\", ascending = False).show()\n",
    "\n",
    "\n",
    "# transform examines the input items against all the association rules and summarize the\n",
    "# consequents as prediction\n",
    "#model.transform(df_fp1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-------------------+------------------+\n",
      "|     antecedent|consequent|         confidence|              lift|\n",
      "+---------------+----------+-------------------+------------------+\n",
      "|[think, people]|    [like]| 0.3843058350100604| 2.272000111588073|\n",
      "|  [think, like]|  [people]| 0.3715953307392996|2.9853650311302373|\n",
      "|        [think]|    [like]| 0.2713833157338965|1.6044068745779339|\n",
      "|        [think]|  [people]| 0.2624076029567054|2.1081601865424244|\n",
      "|        [think]|    [time]| 0.1525871172122492|1.6910499487798067|\n",
      "|        [think]|    [know]| 0.1494192185850053|1.7443492075194047|\n",
      "|        [think]|    [good]|0.13463569165786696| 1.725279005947843|\n",
      "|        [think]|    [much]|0.13357972544878563|1.8329330629561447|\n",
      "|        [think]|     [way]|  0.133051742344245| 2.033450284429608|\n",
      "|        [think]|     [see]|0.11562829989440337|1.7483654991125388|\n",
      "|        [think]|    [want]|0.11351636747624076| 1.926502650422649|\n",
      "|        [think]|  [things]|0.10929250263991552|2.4431099934815195|\n",
      "|        [think]|     [say]|0.10823653643083421|1.9618303563914008|\n",
      "|        [think]|   [thing]|0.10137275607180571|1.9850903875553596|\n",
      "|        [think]|     [lot]|0.09609292502639916| 2.305148986287291|\n",
      "|        [think]|[actually]|0.09503695881731784|1.9070004348096157|\n",
      "|        [think]| [someone]|0.09239704329461457|2.2353531495502783|\n",
      "|        [think]|      [us]|0.09134107708553327| 2.169795836728211|\n",
      "+---------------+----------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display generated association rules.\n",
    "antecedent = 'think'\n",
    "\n",
    "model.associationRules.filter(F.array_contains('antecedent', antecedent)).sort('confidence', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished. Experiment run on 28813 comments. Runtime resulted in 35.32005286216736 seconds.\n"
     ]
    }
   ],
   "source": [
    "### END TIMER\n",
    "\n",
    "end_clock = time()\n",
    "\n",
    "runtime = end_clock - start_clock\n",
    "\n",
    "print(f'Run finished. Experiment run on {sampled_count} comments. Runtime resulted in {runtime} seconds.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
